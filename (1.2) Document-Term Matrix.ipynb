{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 문서 단어 행렬 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "documents = [\"누구나 한번 쯤은 사랑 에 울고\",\n",
    "             \"누구나 한번 쯤은 사랑 에 웃고\",\n",
    "             \"그것이 바로 사랑 사랑 사랑이야\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['누구나', '한번', '쯤은', '사랑', '에', '울고'],\n",
       " ['누구나', '한번', '쯤은', '사랑', '에', '웃고'],\n",
       " ['그것이', '바로', '사랑', '사랑', '사랑이야']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토크나이징\n",
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "docs_tokenized = [tokenizer(d) for d in documents]\n",
    "docs_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 0, 1, 1, 0, 1, 1],\n",
       "       [0, 1, 0, 1, 0, 1, 0, 1, 1, 1],\n",
       "       [1, 0, 1, 2, 1, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=tokenizer)\n",
    "m = vectorizer.fit_transform(documents)\n",
    "m.toarray() # 희소행렬을 넘파이 배열로 # 희소행렬 : 0이 많이 들어 있는 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'누구나': 1,\n",
       " '한번': 9,\n",
       " '쯤은': 8,\n",
       " '사랑': 3,\n",
       " '에': 5,\n",
       " '울고': 6,\n",
       " '웃고': 7,\n",
       " '그것이': 0,\n",
       " '바로': 2,\n",
       " '사랑이야': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 딕셔너리의 key가 가나다 순으로 정렬되어 있습니다.\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>그것이</th>\n",
       "      <th>누구나</th>\n",
       "      <th>바로</th>\n",
       "      <th>사랑</th>\n",
       "      <th>사랑이야</th>\n",
       "      <th>에</th>\n",
       "      <th>울고</th>\n",
       "      <th>웃고</th>\n",
       "      <th>쯤은</th>\n",
       "      <th>한번</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   그것이  누구나  바로  사랑  사랑이야  에  울고  웃고  쯤은  한번\n",
       "0    0    1   0   1     0  1   1   0   1   1\n",
       "1    0    1   0   1     0  1   0   1   1   1\n",
       "2    1    0   1   2     1  0   0   0   0   0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문서-단어 행렬이 의미하는 바는 아래와 같습니다.\n",
    "pd.DataFrame(m.toarray(), \n",
    "             columns=sorted(vectorizer.vocabulary_, key=lambda x: vectorizer.vocabulary_[x]),\n",
    "             dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>그것이</th>\n",
       "      <th>그것이 바로</th>\n",
       "      <th>누구나</th>\n",
       "      <th>누구나 한번</th>\n",
       "      <th>바로</th>\n",
       "      <th>바로 사랑</th>\n",
       "      <th>사랑</th>\n",
       "      <th>사랑 사랑</th>\n",
       "      <th>사랑 사랑이야</th>\n",
       "      <th>사랑 에</th>\n",
       "      <th>사랑이야</th>\n",
       "      <th>에</th>\n",
       "      <th>에 울고</th>\n",
       "      <th>에 웃고</th>\n",
       "      <th>울고</th>\n",
       "      <th>웃고</th>\n",
       "      <th>쯤은</th>\n",
       "      <th>쯤은 사랑</th>\n",
       "      <th>한번</th>\n",
       "      <th>한번 쯤은</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   그것이  그것이 바로  누구나  누구나 한번  바로  바로 사랑  사랑  사랑 사랑  사랑 사랑이야  사랑 에  사랑이야  에  \\\n",
       "0    0       0    1       1   0      0   1      0        0     1     0  1   \n",
       "1    0       0    1       1   0      0   1      0        0     1     0  1   \n",
       "2    1       1    0       0   1      1   2      1        1     0     1  0   \n",
       "\n",
       "   에 울고  에 웃고  울고  웃고  쯤은  쯤은 사랑  한번  한번 쯤은  \n",
       "0     1     0   1   0   1      1   1      1  \n",
       "1     0     1   0   1   1      1   1      1  \n",
       "2     0     0   0   0   0      0   0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer를 이용하면 n-gram도 간단하게 구현할 수 있습니다.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=tokenizer, ngram_range=(1, 2)) # ngram이 하나의 토큰을 만들어 줌\n",
    "m = vectorizer.fit_transform(documents)\n",
    "pd.DataFrame(m.toarray(), \n",
    "             columns=sorted(vectorizer.vocabulary_, key=lambda x: vectorizer.vocabulary_[x]),\n",
    "             dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''“딸에게 미안하다. 감정조절을 못 해 그런 일이 생기게 된 것을 후회한다.”\n",
    "부모로부터 학대를 받은 정황이 드러나 창녕 초등학교 4학년 A양(9)의 친모 C씨(27)가 경찰 조사에서 이런 취지로 이야기한 것으로 드러났다.\n",
    "\n",
    "22일 경남지방경찰청에 따르면 창녕경찰서는 이날 A양의 계부 B씨(35·구속)와와 친모 C씨를 아동복지법 위반 및 아동학대처벌법상 상습특수상해 혐의로 검찰에 송치했다.\n",
    "\n",
    "경찰에 따르면 계부 B씨는 프라이팬으로 A양의 손을 지진 혐의를 받고 있다. 또 여러 차례 A양을 때린 혐의도 받고 있다. 친모 C씨는 쇠사슬로 된 목줄을 A양에게 채운 혐의다. B씨·C씨는 A양의 몸에 난 상처와 관련해서는 대부분 혐의를 인정했으나 일부 혐의를 부인한 것도 있다. 친모 C씨는 A양의 발등과 발바닥을 글루건과 달궈진 젓가락으로 지진 혐의도 받고 있으나 이 부분에 대해서는 혐의를 부인하고 있다.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bd 가나다라'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text2 = \"abcd 가나다라\"\n",
    "re.sub(\"[ac]\", \"\", text2) # a 또는 c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.sub(\"[^ac]\", \"\", text2) # a 또는 c를 제외하고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'딸에게 미안하다 감정조절을 못 해 그런 일이 생기게 된 것을 후회한다부모로부터 학대를 받은 정황이 드러나 창녕 초등학교 학년 양의 친모 씨가 경찰 조사에서 이런 취지로 이야기한 것으로 드러났다일 경남지방경찰청에 따르면 창녕경찰서는 이날 양의 계부 씨구속와와 친모 씨를 아동복지법 위반 및 아동학대처벌법상 상습특수상해 혐의로 검찰에 송치했다경찰에 따르면 계부 씨는 프라이팬으로 양의 손을 지진 혐의를 받고 있다 또 여러 차례 양을 때린 혐의도 받고 있다 친모 씨는 쇠사슬로 된 목줄을 양에게 채운 혐의다 씨씨는 양의 몸에 난 상처와 관련해서는 대부분 혐의를 인정했으나 일부 혐의를 부인한 것도 있다 친모 씨는 양의 발등과 발바닥을 글루건과 달궈진 젓가락으로 지진 혐의도 받고 있으나 이 부분에 대해서는 혐의를 부인하고 있다'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"[^가-힣 ]\",\"\", text) # 한글, 띄어쓰기 제외하고 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"A(9)의 친모 C씨(27)가\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A 의 친모 C씨 가'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"\\(.*?\\)\", \" \", text3) # 괄호 없애기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42857142857142855"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"살아 있는 모든 것은 기억한다\"\n",
    "text2 = \"살아 있는 모든 것이 기억된다\"\n",
    "\n",
    "def jaccard_similarity(d1, d2):\n",
    "    s1 = set(d1.split())\n",
    "    s2 = set(d2.split())\n",
    "    union = set(s1).union(set(s2))\n",
    "    return len(s1&s2) / len(s1|s2)\n",
    "\n",
    "jaccard_similarity(text1, text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'것은', '기억한다', '모든', '살아', '있는'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(text1.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "v1 = np.array([1, 1, 0, 0])\n",
    "v2 = np.array([0, 1, 1, 1])\n",
    "\n",
    "def jaccard_similarity(v1, v2):\n",
    "    i = np.dot(v1, v2) # 같은 위치에 있는 거 비교\n",
    "    u = np.sum(v1) + np.sum(v2) - i # 합집합\n",
    "    return i / u\n",
    "\n",
    "jaccard_similarity(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = np.array([[1, 1, 0, 0, 0],\n",
    "              [1, 1, 0, 0, 0]])\n",
    "v2 = np.array([[1, 0, 1, 1, 0],\n",
    "              [0, 1, 1, 1, 0],\n",
    "              [0, 1, 1, 1, 0]])\n",
    "\n",
    "def jaccard_similarity(v1, v2):\n",
    "    m = np.dot(v1, v2.T) # 교집합의 갯수\n",
    "    s= np.sum(v1, axis=1, keepdims=True) + np.sum(v2.T, axis=0, keepdims=True) -m #합집합\n",
    "    return m/s\n",
    "\n",
    "jaccard_similarity(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.40824829, 0.40824829, 0.40824829],\n",
       "       [0.81649658, 0.40824829, 0.40824829]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# cosine_similarity\n",
    "v1 = np.array([[1, 1, 0, 0, 0],\n",
    "              [1, 0, 1, 0, 0]])\n",
    "\n",
    "v2 = np.array([[1, 0, 1, 1, 0],\n",
    "              [0, 1, 1, 1, 0],\n",
    "              [0, 1, 1, 1, 0]])\n",
    "\n",
    "cosine_similarity(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
